# -*- coding: utf-8 -*-
"""Logistic Regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w-UREZ5_uSAQIUvzuTobgzuoRvN3lmT0
"""

import subprocess

# Install dependencies from requirements.txt
subprocess.check_call(['pip', 'install', '-r', 'requirements.txt']) # upload requirement.txt file

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, roc_auc_score
import streamlit as st

"""# 1. Data Exploration"""

df_train= pd.read_csv('Titanic_train.csv')
df_test= pd.read_csv('Titanic_test.csv')

df_train.head()

df_test.head()

print(df_train.shape)
print(df_test.shape)

df_train.isnull().sum()

df_test.isnull().sum()

df_train.describe()

df_test.describe()

sns.set(style='whitegrid')

# Visualize the distribution of survivors
sns.countplot(x='Survived',data=df_train)
plt.title('Distribution of Survival(0= No, 1= Yes)')
plt.show()

# Visualize the distribution of survivors by gender
sns.countplot(x='Survived', hue='Sex', data=df_train)
plt.title('Survival by Gender')
plt.show()

# Visualize the distribution of survivors by class
sns.countplot(x='Survived', hue='Pclass', data=df_train)
plt.title('Survival by Passenger Class')
plt.show()

# Visualize the age distribution
sns.histplot(df_train['Age'].dropna(), kde=True, bins=30)
plt.title('Age Distribution')
plt.show()

# Check correlation between numerical features and target
plt.title('Correlation Heatmap')
plt.figure(figsize=(10, 8))
sns.heatmap(df_train.corr(), annot=True, cmap='coolwarm')
plt.show()

"""# 2. Data Preprocessing"""

# Handling missing values in 'Age' by filling with median
df_train['Age'].fillna(df_train['Age'].median(), inplace=True)
df_test['Age'].fillna(df_test['Age'].median(), inplace=True)

# Fill missing 'Embarked' values with the most common value
df_train['Embarked'].fillna(df_train['Embarked'].mode()[0], inplace=True)

# Drop 'Cabin' as it contains too many missing values
df_train.drop(columns='Cabin', inplace=True)
df_test.drop(columns='Cabin', inplace=True)

# Drop unnecessary columns for modeling
df_train.drop(columns=['PassengerId', 'Name', 'Ticket'], inplace=True)
df_test.drop(columns=['PassengerId', 'Name', 'Ticket'], inplace=True)

# Convert categorical variables into dummy/indicator variables
df_train = pd.get_dummies(df_train, columns=['Sex', 'Embarked'], drop_first=True)
df_test = pd.get_dummies(df_test, columns=['Sex', 'Embarked'], drop_first=True)

# Ensure both train and test sets have the same dummy variables
missing_cols = set(df_train.columns) - set(df_test.columns)
for col in missing_cols:
    df_test[col] = 0

df_test = df_test[df_train.columns.drop('Survived')]

"""# 3. Model Building:"""

features = df_train.drop(columns='Survived')
target = df_train['Survived']

scaler = StandardScaler()
X = scaler.fit_transform(features)
df_test = scaler.transform(df_test)

model = LogisticRegression()
model.fit(X, target)

y_pred = model.predict(X)

y_pred

"""# 4. Model Evaluation:"""

accuracy = accuracy_score(target, y_pred)
conf_matrix = confusion_matrix(target, y_pred)
class_report = classification_report(target, y_pred)

print("Accuracy score",accuracy)
print("Classification report",class_report)

# Confusion Matrix Heatmap
st.subheader('Confusion Matrix Heatmap')
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
st.pyplot(plt)
plt.show()

# 10. ROC Curve and AUC
y_prob = model.predict_proba(X)[:, 1]
fpr, tpr, thresholds = roc_curve(target, y_prob)
roc_auc = roc_auc_score(target, y_prob)

st.subheader(f'Receiver Operating Characteristic (ROC) Curve - AUC: {roc_auc:.2f}')
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', label=f'ROC Curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
st.pyplot(plt)
plt.show()

"""# Displaying interpretations in Streamlit"""

st.title('Interpretation of Results')
st.write('### Accuracy')
st.write('The accuracy of the model indicates how often the model predicts correctly. In this case, we can see how well the model performed based on the provided data.')

st.write('### Confusion Matrix')
st.write('The confusion matrix helps in understanding the number of true positives, true negatives, false positives, and false negatives.')

st.write('### ROC Curve')
st.write('The ROC Curve and the AUC (Area Under the Curve) score provide insight into the performance of the model at various threshold settings. An AUC close to 1 indicates a good model.')

st.title('Deploying the Model with Streamlit')
st.write('This model is deployed using Streamlit, an open-source app framework. The Streamlit app allows you to visualize data, train models, and interpret results interactively.')

